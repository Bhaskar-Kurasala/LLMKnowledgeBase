Some of the most effective techniques systematically creating smaller, efficient models from LLLMs while preserving performance, sysnthesized from the latest research and practical implementations are:

1. Pruning: Removing Redundant components:
